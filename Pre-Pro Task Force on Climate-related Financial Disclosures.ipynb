{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Task Force on Climate-related Financial Disclosures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script demonstrates the pre-processing of TCFD reports for two insurance companies authorised in the UK, Travelers and St. James's Place, preparing them for further NLP analysis. Task Force on Climate-related Financial Disclosures, provide detailed information on how companies are addressing climate-related risks and opportunities. The transcripts were downloaded from each company's website. Their pre-processing is intricate due to the varied formats and detailed nature of the disclosures, necessitating meticulous handling to ensure data consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from nltk.corpus import words\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for TCFD Reports in Company Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines a function to search for Task Force on Climate-related Financial Disclosures (TCFD) reports within a specified base directory. It looks through directories for banks and insurers, specifically searching for PDF files containing \"tcfd report\" in their names. Some companies include their TCFD reports inside their annual reports, but this script specifically searches for tailored TCFD reports to ensure focused and relevant data collection. The results are returned in a dictionary structure, organized by sector and company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector: Insurers, Company: ST. JAMES place\n",
      "  ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\sjp-tcfd-report-april2020.pdf\n",
      "  ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\sjp-tcfd-report-april2021.pdf\n",
      "  ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\SJP_TCFD_2023.pdf\n",
      "  ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\SJP_TCFD_Report_2022.pdf\n",
      "Sector: Insurers, Company: Traveler Cos TRV\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2019.pdf\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2020.pdf\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2021.pdf\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2022.pdf\n",
      "  ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2023.pdf\n"
     ]
    }
   ],
   "source": [
    "def check_tcfd_reports(base_dir):\n",
    "    results = {}\n",
    "    for sector in [\"Banks\", \"Insurers\"]:\n",
    "        sector_path = os.path.join(base_dir, sector)\n",
    "        if not os.path.isdir(sector_path):\n",
    "            continue\n",
    "        \n",
    "        companies = os.listdir(sector_path)\n",
    "        for company in companies:\n",
    "            company_path = os.path.join(sector_path, company)\n",
    "            if not os.path.isdir(company_path):\n",
    "                continue\n",
    "            \n",
    "            tcfd_path = os.path.join(company_path, \"TCFD\")\n",
    "            if not os.path.isdir(tcfd_path):\n",
    "                continue\n",
    "            \n",
    "            # Look for PDF files with \"tcfd report\" in their name (case insensitive)\n",
    "            for root, dirs, files in os.walk(tcfd_path):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(\".pdf\") and fnmatch.fnmatch(file.lower(), \"*tcfd*.pdf\"):\n",
    "                        if sector not in results:\n",
    "                            results[sector] = {}\n",
    "                        if company not in results[sector]:\n",
    "                            results[sector][company] = []\n",
    "                        results[sector][company].append(os.path.join(root, file))\n",
    "    \n",
    "    return results\n",
    "\n",
    "base_dir = 'ARP BOE'\n",
    "report_files = check_tcfd_reports(base_dir)\n",
    "for sector, companies in report_files.items():\n",
    "    for company, files in companies.items():\n",
    "        print(f\"Sector: {sector}, Company: {company}\")\n",
    "        for file in files:\n",
    "            print(f\"  {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting text out of the PDFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2019.pdf to TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2019.txt\n",
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2020.pdf to TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2020.txt\n",
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2021.pdf to TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2021.txt\n",
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2022.pdf to TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2022.txt\n",
      "Saved text for ARP BOE\\Insurers\\Traveler Cos TRV\\TCFD\\Travelers_TCFDReport2023.pdf to TCFD Texts\\Traveler Cos TRV\\Travelers_TCFDReport2023.txt\n",
      "Saved text for ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\sjp-tcfd-report-april2020.pdf to TCFD Texts\\ST. JAMES place\\sjp-tcfd-report-april2020.txt\n",
      "Saved text for ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\sjp-tcfd-report-april2021.pdf to TCFD Texts\\ST. JAMES place\\sjp-tcfd-report-april2021.txt\n",
      "Saved text for ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\SJP_TCFD_2023.pdf to TCFD Texts\\ST. JAMES place\\SJP_TCFD_2023.txt\n",
      "Saved text for ARP BOE\\Insurers\\ST. JAMES place\\TCFD\\SJP_TCFD_Report_2022.pdf to TCFD Texts\\ST. JAMES place\\SJP_TCFD_Report_2022.txt\n"
     ]
    }
   ],
   "source": [
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            if reader.is_encrypted:\n",
    "                reader.decrypt('')\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def traverse_and_extract_text_for_companies(root_dir, output_dir, companies, max_files_per_folder=10):\n",
    "    total_size = 0\n",
    "\n",
    "    for sector in companies:\n",
    "        for company in companies[sector]:\n",
    "            tcfd_path = os.path.join(root_dir, sector, company, \"TCFD\")\n",
    "            if os.path.isdir(tcfd_path):\n",
    "                company_output_dir = os.path.join(output_dir, company)\n",
    "                os.makedirs(company_output_dir, exist_ok=True)\n",
    "                \n",
    "                file_count = 0\n",
    "                for root, dirs, files in os.walk(tcfd_path):\n",
    "                    for file in files:\n",
    "                        if file.lower().endswith(\".pdf\") and \"tcfd\" in file.lower() and file_count < max_files_per_folder:\n",
    "                            pdf_path = os.path.join(root, file)\n",
    "                            file_size = os.path.getsize(pdf_path)\n",
    "                            text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "                            if text:\n",
    "                                # Save the text as a .txt file\n",
    "                                output_file = os.path.join(company_output_dir, f\"{os.path.splitext(file)[0]}.txt\")\n",
    "                                with open(output_file, 'w', encoding='utf-8') as txt_file:\n",
    "                                    txt_file.write(text)\n",
    "                                print(f\"Saved text for {pdf_path} to {output_file}\")\n",
    "\n",
    "                                total_size += file_size\n",
    "                                file_count += 1\n",
    "\n",
    "                            if file_count >= max_files_per_folder:\n",
    "                                break\n",
    "\n",
    "    return total_size\n",
    "\n",
    "# Root directory path\n",
    "root_dir = \"ARP BOE\"\n",
    "# Output directory path\n",
    "output_dir = \"TCFD Texts\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Specified companies\n",
    "companies = {\n",
    "    \"Insurers\": [\"Traveler Cos TRV\", \"ST. JAMES place\"],\n",
    "}\n",
    "\n",
    "total_size = traverse_and_extract_text_for_companies(root_dir, output_dir, companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tailored Cleaning and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates the cleaning of the TCFDs for Travelers Cos (TRV) and St. James's Place. The script performs several tasks:\n",
    "\n",
    "- Define Cleaning Functions: Includes functions to clean the text by removing headers, footers, special characters and unnecessary spaces.\n",
    "- Specific Cleaning for Each Company: Custom cleaning functions are tailored for the unique formats of the disclosures from each company.\n",
    "- Save Cleaned Texts: The cleaned text files are saved to specified output directories, maintaining the directory structure from the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traveler Cos TRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Travelers_TCFDReport2019.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2019.txt\n",
      "Processed Travelers_TCFDReport2020.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2020.txt\n",
      "Processed Travelers_TCFDReport2021.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2021.txt\n",
      "Processed Travelers_TCFDReport2022.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2022.txt\n",
      "Processed Travelers_TCFDReport2023.txt and saved to Cleaned TCFD Texts/Traveler Cos TRV\\cleaned_Travelers_TCFDReport2023.txt\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the text files\n",
    "input_dir = \"TCFD Texts/Traveler Cos TRV\"\n",
    "output_directory = 'Cleaned TCFD Texts/Traveler Cos TRV'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text, year):\n",
    "    # Remove specific phrase with year\n",
    "    text = re.sub(rf\"Travelers Task Force on Climate-related Financial Disclosures Report\\s*{year}\\s*\\d*\", \"\", text)\n",
    "\n",
    "    # Remove numbered list items ending with a dot (e.g., \"3.\" but not \"3.1\")\n",
    "    text = re.sub(r'\\b\\d+\\.(?!\\d)', \"\", text)\n",
    "\n",
    "    # Remove bullet points\n",
    "    text = re.sub(r'•', \"\", text)\n",
    "\n",
    "    # Remove text starting from \"Important Legal Information\"\n",
    "    text = re.split(r\"Important Legal Information\", text)[0]\n",
    "\n",
    "    # Remove \"Figure\" followed by number and dot or if it is alone in a row\n",
    "    text = re.sub(r'Figure(\\s*\\d+\\.)?', \"\", text)\n",
    "\n",
    "    # Remove bracketed numbers like [1]\n",
    "    text = re.sub(r'\\[\\d+\\]', \"\", text)\n",
    "\n",
    "    # Remove inline numbers within words (e.g., \"1kill\")\n",
    "    text = re.sub(r'(?<=\\D)\\d+(?=\\D)', \"\", text)\n",
    "\n",
    "    # Normalize spaced letters (e.g., e l e c t r i c v e h i c l e to electric vehicle)\n",
    "    text = re.sub(r'\\b(?:[a-zA-Z]\\s)+[a-zA-Z]\\b', lambda m: m.group(0).replace(' ', ''), text)\n",
    "\n",
    "    # Perform additional string replacements\n",
    "    text = re.sub(r'\\*', '', text)\n",
    "    text = re.sub(r'\\[|\\]', '', text)\n",
    "    text = re.sub(r':', '', text)\n",
    "    text = re.sub(r'- Q', '', text)\n",
    "    text = re.sub(r'\\}', '', text)\n",
    "    text = re.sub(r'<|>', '', text)\n",
    "\n",
    "    # Correct words with a full stop between them without space\n",
    "    text = re.sub(r'(\\w)\\.(\\w)', r'\\1. \\2', text)\n",
    "\n",
    "    # Remove specific unwanted strings\n",
    "    text = re.sub(r'‘‘’|’|n/an/a|n/a|®|-K|\\(a\\)|costs\\.sustainability\\.travelers\\. com|- -|\\(\\)|\\(\\$,\\)', '', text)\n",
    "\n",
    "    # Remove patterns like /one. lnum, /two. lnum, /parenleft. lnum, etc.\n",
    "    text = re.sub(r'/[a-zA-Z]+\\. lnum', '', text)\n",
    "\n",
    "    # Split text into lines\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Remove rows based on the year\n",
    "    if year == \"2019\" or year == \"2020\":\n",
    "        lines = lines[3:]  # Remove the first 3 rows\n",
    "    elif year == \"2021\":\n",
    "        lines = lines[11:]  # Remove the first 11 rows\n",
    "    elif year == \"2022\":\n",
    "        lines = lines[13:]  # Remove the first 13 rows\n",
    "    elif year == \"2023\":\n",
    "        lines = lines[15:]  # Remove the first 15 rows\n",
    "\n",
    "    # Remove rows that start with `.%,`, `$.,`, `–`, and any pattern with `(-in-)`\n",
    "    def is_valid_line(line):\n",
    "        line = line.strip()  # Remove leading and trailing whitespace\n",
    "        \n",
    "        # Check for patterns to remove\n",
    "        if re.match(r'^\\s*[\\.\\%,\\$—]', line):\n",
    "            return False\n",
    "        \n",
    "        # Remove lines with patterns like `.%`, `$.`, `(-in-)`, and consecutive symbols like `%%`, `$$`, `$,$,$,`\n",
    "        if re.search(r'\\.%|\\$\\.\\s|\\(-in-\\)|%%|\\$\\$|\\$, \\$, \\$,', line):\n",
    "            return False\n",
    "        \n",
    "        # Remove lines with ™ symbols\n",
    "        if '™' in line:\n",
    "            return False\n",
    "        \n",
    "        # Remove lines with multiple consecutive commas or full stops\n",
    "        if re.search(r'([.,]\\s*){2,}', line):\n",
    "            return False\n",
    "\n",
    "        # Remove lines with only one word or only numbers\n",
    "        if len(line.split()) <= 1 or re.fullmatch(r'\\d+', line.strip()):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    # Apply the validation function to filter lines\n",
    "    filtered_lines = [line for line in lines if is_valid_line(line)]\n",
    "\n",
    "    # Join lines back into text\n",
    "    text = \"\\n\".join(filtered_lines)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Process each text file in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Extract the year from the filename (assuming the format is consistent)\n",
    "        year_match = re.search(r'\\d{4}', filename)\n",
    "        if year_match:\n",
    "            year = year_match.group(0)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Read the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Clean the text\n",
    "        cleaned_text = clean_text(text, year)\n",
    "\n",
    "        # Save the cleaned text back to a file\n",
    "        cleaned_file_path = os.path.join(output_directory, f\"cleaned_{filename}\")\n",
    "        with open(cleaned_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(cleaned_text)\n",
    "\n",
    "        print(f\"Processed {filename} and saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### St. James Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sjp-tcfd-report-april2020.txt and saved to Cleaned TCFD Texts/ST. JAMES place\\cleaned_sjp-tcfd-report-april2020.txt\n",
      "Processed sjp-tcfd-report-april2021.txt and saved to Cleaned TCFD Texts/ST. JAMES place\\cleaned_sjp-tcfd-report-april2021.txt\n",
      "Processed SJP_TCFD_2023.txt and saved to Cleaned TCFD Texts/ST. JAMES place\\cleaned_SJP_TCFD_2023.txt\n",
      "Processed SJP_TCFD_Report_2022.txt and saved to Cleaned TCFD Texts/ST. JAMES place\\cleaned_SJP_TCFD_Report_2022.txt\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the text files\n",
    "input_dir = \"TCFD Texts/ST. JAMES place\"\n",
    "output_directory = 'Cleaned TCFD Texts/ST. JAMES place'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean_text(text, year):\n",
    "    \n",
    "    # Remove specific phrase with year\n",
    "    text = re.sub(rf\"St. James’s Place TCFD Report\\s*{year}\\s*\\d*\", \"\", text)\n",
    "\n",
    "    # Remove specific sections for 2020, including pipes \"|\"\n",
    "    if year == \"2020\":\n",
    "        text = re.sub(r'\\b(?:Introduction|Governance|Strategy|Risk Management|Metrics & Targets|Glossary)\\b', \"\", text)\n",
    "        text = text.replace(\"|\", \"\")\n",
    "\n",
    "        # Remove numbers at the beginning of a word (e.g., \"9cute\" becomes \"cute\")\n",
    "        text = re.sub(r'\\b\\d+([a-zA-Z]+)', r'\\1', text)\n",
    "        \n",
    "        # Remove patterns like \"2           St. James’s Place    TCFD Report\"\n",
    "        text = re.sub(r'^\\d+\\s+St\\. James’s Place\\s+TCFD Report.*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove numbered list items ending with a dot (e.g., \"3.\" but not \"3.1\")\n",
    "    text = re.sub(r'\\b\\d+\\.(?!\\d)', \"\", text)\n",
    "\n",
    "    # Remove bullet points and specific characters (but not \"L\" or \"l\")\n",
    "    text = re.sub(r'•||©', \"\", text)\n",
    "\n",
    "    # Normalize spaced letters (e.g., e l e c t r i c v e h i c l e to electric vehicle)\n",
    "    text = re.sub(r'\\b(?:[a-zA-Z]\\s)+[a-zA-Z]\\b', lambda m: m.group(0).replace(' ', ''), text)\n",
    "\n",
    "    # Split text into lines\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # The first 80 and last 90 rows have been removed, containing contents and legal statements.\n",
    "    if len(lines) > 170:\n",
    "        lines = lines[80:-90]\n",
    "    \n",
    "    # Define patterns for removal\n",
    "    patterns = [\n",
    "        r'^\\s*[a-zA-Z0-9]\\)\\s*',  # Lines starting with \"c)\" or \"1)\"\n",
    "        r'^\\s*#\\d+',              # Lines starting with \"#3\"\n",
    "        r'^\\s*Scope\\b.*',         # Lines starting with \"Scope\"\n",
    "        r'^\\s*[%$\\-].*',          # Lines starting with \"%\", \"$\", or \"-\"\n",
    "        r'^\\s*Pages\\s*\\d+–\\d+\\s*$', # Lines like \"Pages 44–45\"\n",
    "        r'^\\s*Figure(\\s*\\d+\\.)?$', # \"Figure\" alone or followed by number\n",
    "    ]\n",
    "\n",
    "    # Filter lines based on the defined patterns and only keep valid lines\n",
    "    filtered_lines = []\n",
    "    previous_line = None\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.lstrip()  # Remove leading spaces\n",
    "\n",
    "        # Remove lines with only numbers, only letters, or combinations like 'S 0 1'\n",
    "        if (re.match(r'^[0-9\\s,]+$', line.strip()) or \n",
    "            re.match(r'^[a-zA-Z\\s]+$', line.strip()) or \n",
    "            re.match(r'^[a-zA-Z0-9\\s,]+$', line.strip())):\n",
    "            continue\n",
    "        \n",
    "        # Only keep lines that do not match removal criteria\n",
    "        if not any(re.match(pattern, line) for pattern in patterns):\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "    # Remove empty lines\n",
    "    filtered_lines = [line for line in filtered_lines if line.strip()]\n",
    "\n",
    "    # Join lines back into text\n",
    "    text = \"\\n\".join(filtered_lines)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Process each text file in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        # Extract the year from the filename\n",
    "        year_match = re.search(r'\\d{4}', filename)\n",
    "        if year_match:\n",
    "            year = year_match.group(0)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Read the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Clean the text\n",
    "        cleaned_text = clean_text(text, year)\n",
    "\n",
    "        # Save the cleaned text back to a file\n",
    "        cleaned_file_path = os.path.join(output_directory, f\"cleaned_{filename}\")\n",
    "        with open(cleaned_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(cleaned_text)\n",
    "\n",
    "        print(f\"Processed {filename} and saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising Cleaned TCFD Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script extracts and organises cleaned TCFD text data. It performs the following steps:\n",
    "\n",
    "- Data Extraction: Reads text files from directories, extracting the year from file names and the company name from folder names.\n",
    "- Paragraph Identification: Splits text into lines and identifies paragraphs based on end-of-paragraph criteria. \n",
    "- DataFrame Creation: Constructs a DataFrame with columns: `file_name`, `date`, `company_name` and `paragraph`.\n",
    "- Data Sorting: Converts the 'year' column to integers, sorts the DataFrame by company name and year, and ensures proper organisation for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>commitment to help build a long -term future f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Rosemary Hilary , Independent Non -executive  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Group’s risk management frameworkEnsuring exec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>IndividualCross -function working group to dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have explained our approach to meeting thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>O&amp;G Business Unit - Percentage of Total Travel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We expect our renewable energy book of busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Travelers Underwriting Exposure to Carbon  Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>The charts below illustrate the percentage of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We believe  Travelers is well positioned to su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1103 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  date      company_name  \\\n",
       "0     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "2     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "3     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "4     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "...                                     ...   ...               ...   \n",
       "1098   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1099   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1100   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1101   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1102   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                              paragraph  \n",
       "0     commitment to help build a long -term future f...  \n",
       "1     Rosemary Hilary , Independent Non -executive  ...  \n",
       "2     Group’s risk management frameworkEnsuring exec...  \n",
       "3     IndividualCross -function working group to dis...  \n",
       "4     We have explained our approach to meeting thes...  \n",
       "...                                                 ...  \n",
       "1098  O&G Business Unit - Percentage of Total Travel...  \n",
       "1099  We expect our renewable energy book of busines...  \n",
       "1100  Travelers Underwriting Exposure to Carbon  Int...  \n",
       "1101  The charts below illustrate the percentage of ...  \n",
       "1102  We believe  Travelers is well positioned to su...  \n",
       "\n",
       "[1103 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory containing the cleaned text files\n",
    "input_dir = \"Cleaned TCFD Texts\"\n",
    "\n",
    "# Initialize a list to hold the text data\n",
    "text_data = []\n",
    "\n",
    "# Function to determine if a line signifies the end of a paragraph\n",
    "def is_end_of_paragraph(line, next_line):\n",
    "    # End-of-paragraph criteria: line ends with a period and next line starts with a capital letter\n",
    "    return bool(re.search(r'\\.\\s*$', line)) and next_line and next_line[0].isupper()\n",
    "\n",
    "# Iterate over each company folder in the directory\n",
    "for company_folder in os.listdir(input_dir):\n",
    "    company_path = os.path.join(input_dir, company_folder)\n",
    "    if os.path.isdir(company_path):\n",
    "        # Iterate over each text file in the company folder\n",
    "        for filename in os.listdir(company_path):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                file_path = os.path.join(company_path, filename)\n",
    "                \n",
    "                # Extract the date from the filename (4-digit number at the end)\n",
    "                date_match = re.search(r'(\\d{4})\\.txt$', filename)\n",
    "                date = date_match.group(1) if date_match else None\n",
    "\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    text = file.read()\n",
    "                    lines = text.split('\\n')\n",
    "\n",
    "                    # Process the lines to create paragraphs\n",
    "                    if len(lines) > 1:\n",
    "                        company_name = company_folder.replace(\"_\", \" \")  # Get company name from folder\n",
    "                        paragraph = \"\"\n",
    "                        for i in range(2, len(lines)):\n",
    "                            line = lines[i]\n",
    "                            next_line = lines[i + 1] if i + 1 < len(lines) else \"\"\n",
    "                            if is_end_of_paragraph(line, next_line):\n",
    "                                paragraph += line + \" \"\n",
    "                                text_data.append([filename, date, company_name, paragraph.strip()])\n",
    "                                paragraph = \"\"\n",
    "                            else:\n",
    "                                paragraph += line + \" \"\n",
    "                        \n",
    "                        # Add the last paragraph if there is no trailing empty line\n",
    "                        if paragraph:\n",
    "                            text_data.append([filename, date, company_name, paragraph.strip()])\n",
    "\n",
    "# Create a DataFrame with the specified structure\n",
    "paragraphs_df = pd.DataFrame(text_data, columns=['file_name', 'date', 'company_name', 'paragraph'])\n",
    "\n",
    "# Print the new DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate paragraphs are identified and removed, and the DataFrame is reset to ensure continuous indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 1103\n",
      "true_false\n",
      "False    1059\n",
      "True       44\n",
      "Name: count, dtype: int64\n",
      "After: 1059\n"
     ]
    }
   ],
   "source": [
    "# Display the length of the DataFrame before removing duplicates\n",
    "print(\"Before:\", len(paragraphs_df))\n",
    "\n",
    "# Create a copy of the DataFrame to check for duplicates\n",
    "check_dup = paragraphs_df.copy()\n",
    "\n",
    "# Check for duplicate paragraphs\n",
    "check_dup['true_false'] = paragraphs_df.duplicated(subset=['paragraph'])\n",
    "\n",
    "# Display the count of duplicate and unique paragraphs\n",
    "print(check_dup['true_false'].value_counts())\n",
    "\n",
    "# Keep only one row for each unique paragraph\n",
    "paragraphs_df = paragraphs_df.drop_duplicates(subset=['paragraph'])\n",
    "\n",
    "# Reset the index to make sure it's continuous\n",
    "paragraphs_df = paragraphs_df.reset_index(drop=True)\n",
    "\n",
    "# Display the length of the DataFrame after removing duplicates\n",
    "print(\"After:\", len(paragraphs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name\n",
      "cleaned_SJP_TCFD_2023.txt                152\n",
      "cleaned_SJP_TCFD_Report_2022.txt         109\n",
      "cleaned_Travelers_TCFDReport2019.txt      72\n",
      "cleaned_Travelers_TCFDReport2020.txt      95\n",
      "cleaned_Travelers_TCFDReport2021.txt     153\n",
      "cleaned_Travelers_TCFDReport2022.txt     142\n",
      "cleaned_Travelers_TCFDReport2023.txt     209\n",
      "cleaned_sjp-tcfd-report-april2020.txt     39\n",
      "cleaned_sjp-tcfd-report-april2021.txt     88\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "paragraph_counts = paragraphs_df.groupby('file_name').size()\n",
    "print(paragraph_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Specifically, for companies with a low default probability,  most of the risk related to GHG emissions rests with equity  holders. Conversely, for companies with a high default  probability, the risk related to GHG emissions impacts bond  holders to a greater degree than for companies with a low  default probability.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a random paragraph\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    random_paragraph = paragraphs_df['paragraph'].sample(n=1).iloc[0]\n",
    "random_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning and Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script loads a spaCy model and performs text cleaning and post-processing. It includes functions to remove unwanted characters, stop words, numbers, punctuation, and to lemmatize the text. The cleaned text is stored in a new column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1059/1059 [00:19<00:00, 55.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>commitment to help build a long -term future f...</td>\n",
       "      <td>commitment help build long future Force Climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Rosemary Hilary , Independent Non -executive  ...</td>\n",
       "      <td>Rosemary Hilary Independent Non Director chair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Group’s risk management frameworkEnsuring exec...</td>\n",
       "      <td>Group risk management frameworkensuring execut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>IndividualCross -function working group to dis...</td>\n",
       "      <td>individualcross work group discuss emerge ESG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have explained our approach to meeting thes...</td>\n",
       "      <td>explain approach meet objective documentour pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>O&amp;G Business Unit - Percentage of Total Travel...</td>\n",
       "      <td>Business Unit Percentage Total Travelers Domes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We expect our renewable energy book of busines...</td>\n",
       "      <td>expect renewable energy book business continue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Travelers Underwriting Exposure to Carbon  Int...</td>\n",
       "      <td>traveler underwrite exposure Carbon Intensive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>The charts below illustrate the percentage of ...</td>\n",
       "      <td>chart illustrate percentage domestic premium a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We believe  Travelers is well positioned to su...</td>\n",
       "      <td>believe traveler positioned support transition...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  date      company_name  \\\n",
       "0     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "2     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "3     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "4     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "...                                     ...   ...               ...   \n",
       "1054   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1055   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1056   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1057   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1058   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                              paragraph  \\\n",
       "0     commitment to help build a long -term future f...   \n",
       "1     Rosemary Hilary , Independent Non -executive  ...   \n",
       "2     Group’s risk management frameworkEnsuring exec...   \n",
       "3     IndividualCross -function working group to dis...   \n",
       "4     We have explained our approach to meeting thes...   \n",
       "...                                                 ...   \n",
       "1054  O&G Business Unit - Percentage of Total Travel...   \n",
       "1055  We expect our renewable energy book of busines...   \n",
       "1056  Travelers Underwriting Exposure to Carbon  Int...   \n",
       "1057  The charts below illustrate the percentage of ...   \n",
       "1058  We believe  Travelers is well positioned to su...   \n",
       "\n",
       "                                        paragraph_clean  \n",
       "0     commitment help build long future Force Climat...  \n",
       "1     Rosemary Hilary Independent Non Director chair...  \n",
       "2     Group risk management frameworkensuring execut...  \n",
       "3     individualcross work group discuss emerge ESG ...  \n",
       "4     explain approach meet objective documentour pe...  \n",
       "...                                                 ...  \n",
       "1054  Business Unit Percentage Total Travelers Domes...  \n",
       "1055  expect renewable energy book business continue...  \n",
       "1056  traveler underwrite exposure Carbon Intensive ...  \n",
       "1057  chart illustrate percentage domestic premium a...  \n",
       "1058  believe traveler positioned support transition...  \n",
       "\n",
       "[1059 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to clean text in the text_series\n",
    "def clean_text(text_series):\n",
    "    # Convert text_series df to list\n",
    "    text_list = text_series.to_list()\n",
    "\n",
    "    # Remove whitespaces and trailing spaces\n",
    "    def remove_whitespace(text):\n",
    "        pattern = re.compile(r'\\s+')\n",
    "        without_whitespace = re.sub(pattern, ' ', text)\n",
    "        text = without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "    text_list = list(map(lambda x: remove_whitespace(x), text_list))\n",
    "\n",
    "    # Apply NLP pipeline to remove stop words, numbers, and lemmatize the words\n",
    "    cleaned_text_list = []\n",
    "    for text in tqdm(text_list):  # or tqdm.tqdm\n",
    "        doc = nlp(text)\n",
    "        cleaned_text = \" \".join([\n",
    "            token.lemma_\n",
    "            for token in doc\n",
    "            if not token.is_stop\n",
    "            and not token.like_num\n",
    "            and not token.is_punct\n",
    "            and token.is_alpha\n",
    "        ])\n",
    "        cleaned_text_list.append(cleaned_text)\n",
    "    return cleaned_text_list\n",
    "\n",
    "# Function to post-process the DataFrame\n",
    "def post_process(df):\n",
    "    # Create a new column 'paragraph_clean'\n",
    "    df['paragraph_clean'] = df['paragraph']\n",
    "\n",
    "    # Remove unwanted characters and numeric values\n",
    "    df['paragraph_clean'] = df['paragraph_clean'].str.replace(',', '', regex=False)\n",
    "    df['paragraph_clean'] = df['paragraph_clean'].str.replace('.', '', regex=False)\n",
    "    df['paragraph_clean'] = df['paragraph_clean'].str.replace('(', '', regex=False)\n",
    "    df['paragraph_clean'] = df['paragraph_clean'].str.replace(')', '', regex=False)\n",
    "    df['paragraph_clean'] = df['paragraph_clean'].str.replace(r'\\d+\\.\\d+', '', regex=True)\n",
    "    df['paragraph_clean'] = df['paragraph_clean'].str.replace('\\d+', '', regex=True)\n",
    "    df['paragraph_clean'] = df['paragraph_clean'].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply post-processing to the DataFrame\n",
    "paragraphs_df = post_process(paragraphs_df)\n",
    "\n",
    "# Clean the 'paragraph_clean' column\n",
    "paragraphs_df['paragraph_clean'] = clean_text(paragraphs_df['paragraph_clean'])\n",
    "\n",
    "# Set display options and print DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(paragraphs_df['file_name'].nunique())\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Lemmatisation of Cleaned TCFDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code applies lemmatisation to extract nouns from the 'paragraph_clean' column using spaCy and stores the results in a new column 'paragraph_noun'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_clean</th>\n",
       "      <th>paragraph_noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>commitment to help build a long -term future f...</td>\n",
       "      <td>commitment help build long future Force Climat...</td>\n",
       "      <td>commitment help recommendation climate risk di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Rosemary Hilary , Independent Non -executive  ...</td>\n",
       "      <td>Rosemary Hilary Independent Non Director chair...</td>\n",
       "      <td>chair impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Group’s risk management frameworkEnsuring exec...</td>\n",
       "      <td>Group risk management frameworkensuring execut...</td>\n",
       "      <td>risk management execution investment principle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>IndividualCross -function working group to dis...</td>\n",
       "      <td>individualcross work group discuss emerge ESG ...</td>\n",
       "      <td>work group activity climate risk opportunity m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have explained our approach to meeting thes...</td>\n",
       "      <td>explain approach meet objective documentour pe...</td>\n",
       "      <td>approach commitment governance framework frame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>O&amp;G Business Unit - Percentage of Total Travel...</td>\n",
       "      <td>Business Unit Percentage Total Travelers Domes...</td>\n",
       "      <td>business percentage total traveler traveler pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We expect our renewable energy book of busines...</td>\n",
       "      <td>expect renewable energy book business continue...</td>\n",
       "      <td>energy book business time progress business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Travelers Underwriting Exposure to Carbon  Int...</td>\n",
       "      <td>traveler underwrite exposure Carbon Intensive ...</td>\n",
       "      <td>traveler exposure carbon sector classification...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>The charts below illustrate the percentage of ...</td>\n",
       "      <td>chart illustrate percentage domestic premium a...</td>\n",
       "      <td>chart percentage premium associate carbon sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We believe  Travelers is well positioned to su...</td>\n",
       "      <td>believe traveler positioned support transition...</td>\n",
       "      <td>traveler support transition carbon economy tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  date      company_name  \\\n",
       "0     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "2     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "3     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "4     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "...                                     ...   ...               ...   \n",
       "1054   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1055   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1056   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1057   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1058   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                              paragraph  \\\n",
       "0     commitment to help build a long -term future f...   \n",
       "1     Rosemary Hilary , Independent Non -executive  ...   \n",
       "2     Group’s risk management frameworkEnsuring exec...   \n",
       "3     IndividualCross -function working group to dis...   \n",
       "4     We have explained our approach to meeting thes...   \n",
       "...                                                 ...   \n",
       "1054  O&G Business Unit - Percentage of Total Travel...   \n",
       "1055  We expect our renewable energy book of busines...   \n",
       "1056  Travelers Underwriting Exposure to Carbon  Int...   \n",
       "1057  The charts below illustrate the percentage of ...   \n",
       "1058  We believe  Travelers is well positioned to su...   \n",
       "\n",
       "                                        paragraph_clean  \\\n",
       "0     commitment help build long future Force Climat...   \n",
       "1     Rosemary Hilary Independent Non Director chair...   \n",
       "2     Group risk management frameworkensuring execut...   \n",
       "3     individualcross work group discuss emerge ESG ...   \n",
       "4     explain approach meet objective documentour pe...   \n",
       "...                                                 ...   \n",
       "1054  Business Unit Percentage Total Travelers Domes...   \n",
       "1055  expect renewable energy book business continue...   \n",
       "1056  traveler underwrite exposure Carbon Intensive ...   \n",
       "1057  chart illustrate percentage domestic premium a...   \n",
       "1058  believe traveler positioned support transition...   \n",
       "\n",
       "                                         paragraph_noun  \n",
       "0     commitment help recommendation climate risk di...  \n",
       "1                                          chair impact  \n",
       "2     risk management execution investment principle...  \n",
       "3     work group activity climate risk opportunity m...  \n",
       "4     approach commitment governance framework frame...  \n",
       "...                                                 ...  \n",
       "1054  business percentage total traveler traveler pr...  \n",
       "1055        energy book business time progress business  \n",
       "1056  traveler exposure carbon sector classification...  \n",
       "1057  chart percentage premium associate carbon sect...  \n",
       "1058  traveler support transition carbon economy tim...  \n",
       "\n",
       "[1059 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Lemmatization function\n",
    "def lemmatization(texts, allowed_postags=[\"NOUN\"]):\n",
    "    doc = nlp(texts)\n",
    "    new_text = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in allowed_postags:\n",
    "            new_text.append(token.lemma_)\n",
    "    final = \" \".join(new_text)\n",
    "    return final\n",
    "\n",
    "# Apply lemmatization to the 'paragraph_clean' column\n",
    "paragraphs_df['paragraph_noun'] = paragraphs_df['paragraph_clean'].apply(lemmatization)\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(paragraphs_df['file_name'].nunique())\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'paragraph_noun' if it is not in English\n",
    "paragraphs_df = paragraphs_df[paragraphs_df['paragraph_noun'].str.contains('[a-zA-Z]')]\n",
    "paragraphs_df = paragraphs_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenising and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script performs detailed text tokenisation and filtering on TCFD disclosures. The steps involve defining functions to clean, tokenise text and removing general words that are not useful for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dimi3\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "100%|██████████| 1054/1054 [00:04<00:00, 262.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_clean</th>\n",
       "      <th>paragraph_noun</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>commitment to help build a long -term future f...</td>\n",
       "      <td>commitment help build long future Force Climat...</td>\n",
       "      <td>commitment help recommendation climate risk di...</td>\n",
       "      <td>[commitment, help, recommendation, climate, ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Rosemary Hilary , Independent Non -executive  ...</td>\n",
       "      <td>Rosemary Hilary Independent Non Director chair...</td>\n",
       "      <td>chair impact</td>\n",
       "      <td>[chair, impact]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Group’s risk management frameworkEnsuring exec...</td>\n",
       "      <td>Group risk management frameworkensuring execut...</td>\n",
       "      <td>risk management execution investment principle...</td>\n",
       "      <td>[risk, management, execution, investment, prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>IndividualCross -function working group to dis...</td>\n",
       "      <td>individualcross work group discuss emerge ESG ...</td>\n",
       "      <td>work group activity climate risk opportunity m...</td>\n",
       "      <td>[work, group, activity, climate, risk, opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have explained our approach to meeting thes...</td>\n",
       "      <td>explain approach meet objective documentour pe...</td>\n",
       "      <td>approach commitment governance framework frame...</td>\n",
       "      <td>[approach, commitment, governance, framework, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>O&amp;G Business Unit - Percentage of Total Travel...</td>\n",
       "      <td>Business Unit Percentage Total Travelers Domes...</td>\n",
       "      <td>business percentage total traveler traveler pr...</td>\n",
       "      <td>[business, percentage, total, traveler, travel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We expect our renewable energy book of busines...</td>\n",
       "      <td>expect renewable energy book business continue...</td>\n",
       "      <td>energy book business time progress business</td>\n",
       "      <td>[energy, book, business, time, progress, busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Travelers Underwriting Exposure to Carbon  Int...</td>\n",
       "      <td>traveler underwrite exposure Carbon Intensive ...</td>\n",
       "      <td>traveler exposure carbon sector classification...</td>\n",
       "      <td>[traveler, exposure, carbon, sector, classific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>The charts below illustrate the percentage of ...</td>\n",
       "      <td>chart illustrate percentage domestic premium a...</td>\n",
       "      <td>chart percentage premium associate carbon sect...</td>\n",
       "      <td>[chart, percentage, premium, associate, carbon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We believe  Travelers is well positioned to su...</td>\n",
       "      <td>believe traveler positioned support transition...</td>\n",
       "      <td>traveler support transition carbon economy tim...</td>\n",
       "      <td>[traveler, support, transition, carbon, econom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  date      company_name  \\\n",
       "0     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "2     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "3     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "4     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "...                                     ...   ...               ...   \n",
       "1049   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1050   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1051   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1052   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1053   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                              paragraph  \\\n",
       "0     commitment to help build a long -term future f...   \n",
       "1     Rosemary Hilary , Independent Non -executive  ...   \n",
       "2     Group’s risk management frameworkEnsuring exec...   \n",
       "3     IndividualCross -function working group to dis...   \n",
       "4     We have explained our approach to meeting thes...   \n",
       "...                                                 ...   \n",
       "1049  O&G Business Unit - Percentage of Total Travel...   \n",
       "1050  We expect our renewable energy book of busines...   \n",
       "1051  Travelers Underwriting Exposure to Carbon  Int...   \n",
       "1052  The charts below illustrate the percentage of ...   \n",
       "1053  We believe  Travelers is well positioned to su...   \n",
       "\n",
       "                                        paragraph_clean  \\\n",
       "0     commitment help build long future Force Climat...   \n",
       "1     Rosemary Hilary Independent Non Director chair...   \n",
       "2     Group risk management frameworkensuring execut...   \n",
       "3     individualcross work group discuss emerge ESG ...   \n",
       "4     explain approach meet objective documentour pe...   \n",
       "...                                                 ...   \n",
       "1049  Business Unit Percentage Total Travelers Domes...   \n",
       "1050  expect renewable energy book business continue...   \n",
       "1051  traveler underwrite exposure Carbon Intensive ...   \n",
       "1052  chart illustrate percentage domestic premium a...   \n",
       "1053  believe traveler positioned support transition...   \n",
       "\n",
       "                                         paragraph_noun  \\\n",
       "0     commitment help recommendation climate risk di...   \n",
       "1                                          chair impact   \n",
       "2     risk management execution investment principle...   \n",
       "3     work group activity climate risk opportunity m...   \n",
       "4     approach commitment governance framework frame...   \n",
       "...                                                 ...   \n",
       "1049  business percentage total traveler traveler pr...   \n",
       "1050        energy book business time progress business   \n",
       "1051  traveler exposure carbon sector classification...   \n",
       "1052  chart percentage premium associate carbon sect...   \n",
       "1053  traveler support transition carbon economy tim...   \n",
       "\n",
       "                                                  token  \n",
       "0     [commitment, help, recommendation, climate, ri...  \n",
       "1                                       [chair, impact]  \n",
       "2     [risk, management, execution, investment, prin...  \n",
       "3     [work, group, activity, climate, risk, opportu...  \n",
       "4     [approach, commitment, governance, framework, ...  \n",
       "...                                                 ...  \n",
       "1049  [business, percentage, total, traveler, travel...  \n",
       "1050  [energy, book, business, time, progress, busin...  \n",
       "1051  [traveler, exposure, carbon, sector, classific...  \n",
       "1052  [chart, percentage, premium, associate, carbon...  \n",
       "1053  [traveler, support, transition, carbon, econom...  \n",
       "\n",
       "[1054 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Load a set of common English words\n",
    "nltk.download('words')\n",
    "english_words = set(words.words())\n",
    "\n",
    "def clean_tokens_noun(text_series):\n",
    "    # Step 1: Convert text_series df to list\n",
    "    text_list = text_series.to_list()\n",
    "\n",
    "    # Step 2: Change the list to lower case\n",
    "    text_list = [x.lower() for x in text_list]\n",
    "\n",
    "    # Step 3: Remove whitespaces and trailing spaces\n",
    "    def remove_whitespace(text):\n",
    "        pattern = re.compile(r'\\s+')\n",
    "        without_whitespace = re.sub(pattern, ' ', text)\n",
    "        text = without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "    text_list = [remove_whitespace(x) for x in text_list]\n",
    "\n",
    "    # Step 4: Process tokens and remove non-English words, single letters, and numbers\n",
    "    tokens = []\n",
    "    for text in tqdm(text_list):\n",
    "        doc = nlp(text)\n",
    "        tmp_tokens = [\n",
    "            token.lemma_\n",
    "            for token in doc\n",
    "            if not token.is_stop\n",
    "            and not token.like_num\n",
    "            and not token.is_punct\n",
    "            and token.is_alpha\n",
    "            and token.lemma_ in english_words  # Only include English words\n",
    "            and len(token.lemma_) > 1           # Exclude single letters\n",
    "        ]\n",
    "        tokens.append(tmp_tokens)\n",
    "    return tokens\n",
    "\n",
    "# Apply the clean_tokens_noun function to get the tokens of the 'paragraph_noun' column\n",
    "paragraphs_df['token'] = clean_tokens_noun(paragraphs_df['paragraph_noun'])\n",
    "\n",
    "# Print the length of the DataFrame and display it\n",
    "print(len(paragraphs_df))\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_clean</th>\n",
       "      <th>paragraph_noun</th>\n",
       "      <th>token</th>\n",
       "      <th>word_count</th>\n",
       "      <th>characters_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>commitment to help build a long -term future f...</td>\n",
       "      <td>commitment help build long future Force Climat...</td>\n",
       "      <td>commitment help recommendation climate risk di...</td>\n",
       "      <td>[commitment, help, recommendation, climate, ri...</td>\n",
       "      <td>89</td>\n",
       "      <td>626</td>\n",
       "      <td>10</td>\n",
       "      <td>7.033708</td>\n",
       "      <td>8.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Rosemary Hilary , Independent Non -executive  ...</td>\n",
       "      <td>Rosemary Hilary Independent Non Director chair...</td>\n",
       "      <td>chair impact</td>\n",
       "      <td>[chair, impact]</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Group’s risk management frameworkEnsuring exec...</td>\n",
       "      <td>Group risk management frameworkensuring execut...</td>\n",
       "      <td>risk management execution investment principle...</td>\n",
       "      <td>[risk, management, execution, investment, prin...</td>\n",
       "      <td>14</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>IndividualCross -function working group to dis...</td>\n",
       "      <td>individualcross work group discuss emerge ESG ...</td>\n",
       "      <td>work group activity climate risk opportunity m...</td>\n",
       "      <td>[work, group, activity, climate, risk, opportu...</td>\n",
       "      <td>38</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>6.736842</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have explained our approach to meeting thes...</td>\n",
       "      <td>explain approach meet objective documentour pe...</td>\n",
       "      <td>approach commitment governance framework frame...</td>\n",
       "      <td>[approach, commitment, governance, framework, ...</td>\n",
       "      <td>68</td>\n",
       "      <td>514</td>\n",
       "      <td>13</td>\n",
       "      <td>7.558824</td>\n",
       "      <td>5.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>O&amp;G Business Unit - Percentage of Total Travel...</td>\n",
       "      <td>Business Unit Percentage Total Travelers Domes...</td>\n",
       "      <td>business percentage total traveler traveler pr...</td>\n",
       "      <td>[business, percentage, total, traveler, travel...</td>\n",
       "      <td>71</td>\n",
       "      <td>486</td>\n",
       "      <td>8</td>\n",
       "      <td>6.845070</td>\n",
       "      <td>8.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We expect our renewable energy book of busines...</td>\n",
       "      <td>expect renewable energy book business continue...</td>\n",
       "      <td>energy book business time progress business</td>\n",
       "      <td>[energy, book, business, time, progress, busin...</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Travelers Underwriting Exposure to Carbon  Int...</td>\n",
       "      <td>traveler underwrite exposure Carbon Intensive ...</td>\n",
       "      <td>traveler exposure carbon sector classification...</td>\n",
       "      <td>[traveler, exposure, carbon, sector, classific...</td>\n",
       "      <td>24</td>\n",
       "      <td>166</td>\n",
       "      <td>4</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>The charts below illustrate the percentage of ...</td>\n",
       "      <td>chart illustrate percentage domestic premium a...</td>\n",
       "      <td>chart percentage premium associate carbon sect...</td>\n",
       "      <td>[chart, percentage, premium, associate, carbon...</td>\n",
       "      <td>34</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>7.617647</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We believe  Travelers is well positioned to su...</td>\n",
       "      <td>believe traveler positioned support transition...</td>\n",
       "      <td>traveler support transition carbon economy tim...</td>\n",
       "      <td>[traveler, support, transition, carbon, econom...</td>\n",
       "      <td>34</td>\n",
       "      <td>244</td>\n",
       "      <td>7</td>\n",
       "      <td>7.176471</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  file_name  date      company_name  \\\n",
       "0     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "2     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "3     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "4     cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "...                                     ...   ...               ...   \n",
       "1049   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1050   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1051   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1052   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "1053   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                              paragraph  \\\n",
       "0     commitment to help build a long -term future f...   \n",
       "1     Rosemary Hilary , Independent Non -executive  ...   \n",
       "2     Group’s risk management frameworkEnsuring exec...   \n",
       "3     IndividualCross -function working group to dis...   \n",
       "4     We have explained our approach to meeting thes...   \n",
       "...                                                 ...   \n",
       "1049  O&G Business Unit - Percentage of Total Travel...   \n",
       "1050  We expect our renewable energy book of busines...   \n",
       "1051  Travelers Underwriting Exposure to Carbon  Int...   \n",
       "1052  The charts below illustrate the percentage of ...   \n",
       "1053  We believe  Travelers is well positioned to su...   \n",
       "\n",
       "                                        paragraph_clean  \\\n",
       "0     commitment help build long future Force Climat...   \n",
       "1     Rosemary Hilary Independent Non Director chair...   \n",
       "2     Group risk management frameworkensuring execut...   \n",
       "3     individualcross work group discuss emerge ESG ...   \n",
       "4     explain approach meet objective documentour pe...   \n",
       "...                                                 ...   \n",
       "1049  Business Unit Percentage Total Travelers Domes...   \n",
       "1050  expect renewable energy book business continue...   \n",
       "1051  traveler underwrite exposure Carbon Intensive ...   \n",
       "1052  chart illustrate percentage domestic premium a...   \n",
       "1053  believe traveler positioned support transition...   \n",
       "\n",
       "                                         paragraph_noun  \\\n",
       "0     commitment help recommendation climate risk di...   \n",
       "1                                          chair impact   \n",
       "2     risk management execution investment principle...   \n",
       "3     work group activity climate risk opportunity m...   \n",
       "4     approach commitment governance framework frame...   \n",
       "...                                                 ...   \n",
       "1049  business percentage total traveler traveler pr...   \n",
       "1050        energy book business time progress business   \n",
       "1051  traveler exposure carbon sector classification...   \n",
       "1052  chart percentage premium associate carbon sect...   \n",
       "1053  traveler support transition carbon economy tim...   \n",
       "\n",
       "                                                  token  word_count  \\\n",
       "0     [commitment, help, recommendation, climate, ri...          89   \n",
       "1                                       [chair, impact]           2   \n",
       "2     [risk, management, execution, investment, prin...          14   \n",
       "3     [work, group, activity, climate, risk, opportu...          38   \n",
       "4     [approach, commitment, governance, framework, ...          68   \n",
       "...                                                 ...         ...   \n",
       "1049  [business, percentage, total, traveler, travel...          71   \n",
       "1050  [energy, book, business, time, progress, busin...           6   \n",
       "1051  [traveler, exposure, carbon, sector, classific...          24   \n",
       "1052  [chart, percentage, premium, associate, carbon...          34   \n",
       "1053  [traveler, support, transition, carbon, econom...          34   \n",
       "\n",
       "      characters_count  sentence_count  avg_word_length  avg_sentence_length  \n",
       "0                  626              10         7.033708             8.900000  \n",
       "1                   11               3         5.500000             0.666667  \n",
       "2                  105               4         7.500000             3.500000  \n",
       "3                  256               8         6.736842             4.750000  \n",
       "4                  514              13         7.558824             5.230769  \n",
       "...                ...             ...              ...                  ...  \n",
       "1049               486               8         6.845070             8.875000  \n",
       "1050                38               2         6.333333             3.000000  \n",
       "1051               166               4         6.916667             6.000000  \n",
       "1052               259               5         7.617647             6.800000  \n",
       "1053               244               7         7.176471             4.857143  \n",
       "\n",
       "[1054 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column for length analysis outcome\n",
    "paragraphs_df['word_count'] = paragraphs_df[\"token\"].apply(lambda x: len(x))\n",
    "paragraphs_df['characters_count'] = paragraphs_df[\"token\"].apply(lambda x: sum(len(word) for word in x))\n",
    "paragraphs_df['sentence_count'] = paragraphs_df['paragraph'].apply(lambda x: len(str(x).split(\".\")))\n",
    "paragraphs_df['avg_word_length'] = paragraphs_df['characters_count'] / paragraphs_df['word_count']\n",
    "paragraphs_df['avg_sentence_length'] = paragraphs_df['word_count'] / paragraphs_df['sentence_count']\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude rows where sentence_count is less than 3\n",
    "paragraphs_df = paragraphs_df[paragraphs_df['sentence_count'] > 3]\n",
    "# Reset the index\n",
    "paragraphs_df = paragraphs_df.reset_index(drop=True)\n",
    "# Display the length of the DataFrame\n",
    "len(paragraphs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_clean</th>\n",
       "      <th>paragraph_noun</th>\n",
       "      <th>token</th>\n",
       "      <th>word_count</th>\n",
       "      <th>characters_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>commitment to help build a long -term future f...</td>\n",
       "      <td>commitment help build long future Force Climat...</td>\n",
       "      <td>commitment help recommendation climate risk di...</td>\n",
       "      <td>[commitment, help, recommendation, climate, di...</td>\n",
       "      <td>89</td>\n",
       "      <td>626</td>\n",
       "      <td>10</td>\n",
       "      <td>7.033708</td>\n",
       "      <td>8.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Group’s risk management frameworkEnsuring exec...</td>\n",
       "      <td>Group risk management frameworkensuring execut...</td>\n",
       "      <td>risk management execution investment principle...</td>\n",
       "      <td>[principle, framework, place, climate, climate...</td>\n",
       "      <td>14</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>IndividualCross -function working group to dis...</td>\n",
       "      <td>individualcross work group discuss emerge ESG ...</td>\n",
       "      <td>work group activity climate risk opportunity m...</td>\n",
       "      <td>[work, group, activity, climate, climate, team...</td>\n",
       "      <td>38</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>6.736842</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have explained our approach to meeting thes...</td>\n",
       "      <td>explain approach meet objective documentour pe...</td>\n",
       "      <td>approach commitment governance framework frame...</td>\n",
       "      <td>[approach, commitment, governance, framework, ...</td>\n",
       "      <td>68</td>\n",
       "      <td>514</td>\n",
       "      <td>13</td>\n",
       "      <td>7.558824</td>\n",
       "      <td>5.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have facilitated regular cross -function di...</td>\n",
       "      <td>facilitate regular cross discussion identify p...</td>\n",
       "      <td>cross discussion eg increase frequency weather...</td>\n",
       "      <td>[cross, frequency, weather, event, transition,...</td>\n",
       "      <td>33</td>\n",
       "      <td>233</td>\n",
       "      <td>11</td>\n",
       "      <td>7.060606</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Importantly, all of our top  Oil &amp; Gas distrib...</td>\n",
       "      <td>importantly Oil Gas distribution partner sell ...</td>\n",
       "      <td>distribution partner traveler insurance produc...</td>\n",
       "      <td>[distribution, partner, traveler, insurance, f...</td>\n",
       "      <td>24</td>\n",
       "      <td>178</td>\n",
       "      <td>4</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>O&amp;G Business Unit - Percentage of Total Travel...</td>\n",
       "      <td>Business Unit Percentage Total Travelers Domes...</td>\n",
       "      <td>business percentage total traveler traveler pr...</td>\n",
       "      <td>[percentage, total, traveler, traveler, suppor...</td>\n",
       "      <td>71</td>\n",
       "      <td>486</td>\n",
       "      <td>8</td>\n",
       "      <td>6.845070</td>\n",
       "      <td>8.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Travelers Underwriting Exposure to Carbon  Int...</td>\n",
       "      <td>traveler underwrite exposure Carbon Intensive ...</td>\n",
       "      <td>traveler exposure carbon sector classification...</td>\n",
       "      <td>[traveler, exposure, carbon, classification, t...</td>\n",
       "      <td>24</td>\n",
       "      <td>166</td>\n",
       "      <td>4</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>The charts below illustrate the percentage of ...</td>\n",
       "      <td>chart illustrate percentage domestic premium a...</td>\n",
       "      <td>chart percentage premium associate carbon sect...</td>\n",
       "      <td>[chart, percentage, premium, associate, carbon...</td>\n",
       "      <td>34</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>7.617647</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We believe  Travelers is well positioned to su...</td>\n",
       "      <td>believe traveler positioned support transition...</td>\n",
       "      <td>traveler support transition carbon economy tim...</td>\n",
       "      <td>[traveler, support, transition, carbon, econom...</td>\n",
       "      <td>34</td>\n",
       "      <td>244</td>\n",
       "      <td>7</td>\n",
       "      <td>7.176471</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name  date      company_name  \\\n",
       "0    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "2    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "3    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "4    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "..                                     ...   ...               ...   \n",
       "619   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "620   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "621   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "622   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "623   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                             paragraph  \\\n",
       "0    commitment to help build a long -term future f...   \n",
       "1    Group’s risk management frameworkEnsuring exec...   \n",
       "2    IndividualCross -function working group to dis...   \n",
       "3    We have explained our approach to meeting thes...   \n",
       "4    We have facilitated regular cross -function di...   \n",
       "..                                                 ...   \n",
       "619  Importantly, all of our top  Oil & Gas distrib...   \n",
       "620  O&G Business Unit - Percentage of Total Travel...   \n",
       "621  Travelers Underwriting Exposure to Carbon  Int...   \n",
       "622  The charts below illustrate the percentage of ...   \n",
       "623  We believe  Travelers is well positioned to su...   \n",
       "\n",
       "                                       paragraph_clean  \\\n",
       "0    commitment help build long future Force Climat...   \n",
       "1    Group risk management frameworkensuring execut...   \n",
       "2    individualcross work group discuss emerge ESG ...   \n",
       "3    explain approach meet objective documentour pe...   \n",
       "4    facilitate regular cross discussion identify p...   \n",
       "..                                                 ...   \n",
       "619  importantly Oil Gas distribution partner sell ...   \n",
       "620  Business Unit Percentage Total Travelers Domes...   \n",
       "621  traveler underwrite exposure Carbon Intensive ...   \n",
       "622  chart illustrate percentage domestic premium a...   \n",
       "623  believe traveler positioned support transition...   \n",
       "\n",
       "                                        paragraph_noun  \\\n",
       "0    commitment help recommendation climate risk di...   \n",
       "1    risk management execution investment principle...   \n",
       "2    work group activity climate risk opportunity m...   \n",
       "3    approach commitment governance framework frame...   \n",
       "4    cross discussion eg increase frequency weather...   \n",
       "..                                                 ...   \n",
       "619  distribution partner traveler insurance produc...   \n",
       "620  business percentage total traveler traveler pr...   \n",
       "621  traveler exposure carbon sector classification...   \n",
       "622  chart percentage premium associate carbon sect...   \n",
       "623  traveler support transition carbon economy tim...   \n",
       "\n",
       "                                                 token  word_count  \\\n",
       "0    [commitment, help, recommendation, climate, di...          89   \n",
       "1    [principle, framework, place, climate, climate...          14   \n",
       "2    [work, group, activity, climate, climate, team...          38   \n",
       "3    [approach, commitment, governance, framework, ...          68   \n",
       "4    [cross, frequency, weather, event, transition,...          33   \n",
       "..                                                 ...         ...   \n",
       "619  [distribution, partner, traveler, insurance, f...          24   \n",
       "620  [percentage, total, traveler, traveler, suppor...          71   \n",
       "621  [traveler, exposure, carbon, classification, t...          24   \n",
       "622  [chart, percentage, premium, associate, carbon...          34   \n",
       "623  [traveler, support, transition, carbon, econom...          34   \n",
       "\n",
       "     characters_count  sentence_count  avg_word_length  avg_sentence_length  \n",
       "0                 626              10         7.033708             8.900000  \n",
       "1                 105               4         7.500000             3.500000  \n",
       "2                 256               8         6.736842             4.750000  \n",
       "3                 514              13         7.558824             5.230769  \n",
       "4                 233              11         7.060606             3.000000  \n",
       "..                ...             ...              ...                  ...  \n",
       "619               178               4         7.416667             6.000000  \n",
       "620               486               8         6.845070             8.875000  \n",
       "621               166               4         6.916667             6.000000  \n",
       "622               259               5         7.617647             6.800000  \n",
       "623               244               7         7.176471             4.857143  \n",
       "\n",
       "[624 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the words that are too general for earnings calls\n",
    "general_words = [\n",
    "    'lady', 'gentleman', 'presentation',\n",
    "    'question', 'answer', 'slide', 'mm', 'mm_mm', 'guy', 'sir', ' ', 'ytd', 'host_sir',\n",
    "    'bb', 'ty', 'word', 'year', 'quer', 'month', 'period', 'day', 'time', 'result',\n",
    "    'investor', 'week', 'update', 'business', 'lot', 'ratio', 'rate', 'quarter',\n",
    "    'number', 'point', 'term', 'thing', 'level', 'bit', 'sort', 'reason', 'management',\n",
    "    'fact', 'case', 'area', 'people', 'sense', 'item', 'issue', 'market', 'meeting',\n",
    "    'questions', 'answers', 'managements', 'discussion', 'section', 'presentation', \n",
    "    'speaker', 'participant', 'afternoon', 'morning', 'conference', 'today', 'lady', \n",
    "    'gentleman', 'presentation', 'question', 'answer', 'slide',\n",
    "    'mm', 'mm_mm', 'guy', 'sir', 'host_sir', 'bb', 'ty', 'word', 'year', 'quer',\n",
    "    'month', 'period', 'day', 'time', 'result', 'investor', 'week', 'update', 'business', 'lot', 'ratio', 'rate', 'quarter',\n",
    "    'number', 'point', 'term', 'thing', 'level', 'bit', 'sort', 'reason', 'management',\n",
    "    'fact', 'case', 'area', 'people', 'sense', 'item', 'issue', 'market', 'earnings',\n",
    "    'report', 'financial', 'results', 'quarterly', 'performance', 'guidance', 'statement',\n",
    "    'outlook', 'projection', 'profit', 'loss', 'revenue', 'sales', 'expense', 'income',\n",
    "    'cash', 'flow', 'margin', 'growth', 'decline', 'increase', 'decrease', 'forecast',\n",
    "    'expectation', 'trend', 'metric', 'indicator', 'shareholder', 'stock', 'price', 'value',\n",
    "    'equity', 'debt', 'asset', 'liability', 'balance', 'sheet', 'capital', 'investment',\n",
    "    'portfolio', 'dividend', 'yield', 'ratio', 'return', 'earnings', 'per', 'share', 'EPS',\n",
    "    'acquisition', 'merger', 'synergy', 'integration', 'strategy', 'execution', 'plan',\n",
    "    'objective', 'goal', 'target', 'vision', 'mission', 'operation', 'process', 'initiative',\n",
    "    'efficiency', 'optimization', 'innovation', 'technology', 'product', 'service', 'customer',\n",
    "    'client', 'market', 'segment', 'competition', 'competitor', 'industry', 'sector', 'environment',\n",
    "    'regulation', 'compliance', 'risk', 'opportunity', 'challenge', 'threat', 'advantage',\n",
    "    'disadvantage', 'strength', 'weakness', 'SWOT', 'analysis', 'review', 'summary',\n",
    "    'highlight', 'detail', 'report', 'note', 'comment', 'announcement', 'release', 'update','tcfd, Severe wind and hail n an a n an a, Hurricane n a n a, Winter storm n a n a'\n",
    "]\n",
    "\n",
    "# Apply the filtering to your DataFrame\n",
    "paragraphs_df['token'] = paragraphs_df['token'].apply(lambda x: [i for i in x if i not in general_words])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Cleaning Frequent Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script extracts the 5 most frequent words from the TCFD disclosures for each paragraph per file and cleans the tokens by removing them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.93it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 189.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.73it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.02it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 336.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 21.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.60it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.04it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.42it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 309.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 151.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 190.29it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.66it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.98it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.35it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1708.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.47it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.72it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 249.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.96it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.28it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.86it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.86it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 498.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7133.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.90it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.78it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.85it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.54it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 865.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.94it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.90it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.08it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.94it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 202.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1169.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.93it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.04it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.85it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.97it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 189.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 175.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 215.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 237.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.81it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.30it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.15it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.31it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.98it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.51it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.03it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.90it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.97it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.93it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 335.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 227.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 169.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 264.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 30.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 234.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 469.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 201.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 167.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1028.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 281.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 234.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 217.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 186.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 638.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 176.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 297.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 230.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 151.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 196.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 318.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 203.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(climate, 26), (risk, 19), (opportunity, 7), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(risk, 3), (investment, 3), (responsible, 2),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(climate, 5), (risk, 4), (st, 3), (place, 3),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(climate, 10), (investment, 4), (risk, 3), (r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[(risk, 3), (change, 2), (opportunity, 2), (bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(premium, 4), (insurance, 3), (oil, 2), (gas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(energy, 14), (renewable, 11), (traveler, 4),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(carbon, 3), (premium, 3), (continue, 3), (tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(vehicle, 7), (percentage, 5), (premium, 4), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[(energy, 4), (evolve, 3), (traveler, 2), (sup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name      company_name  \\\n",
       "0    cleaned_sjp-tcfd-report-april2020.txt   ST. JAMES place   \n",
       "1    cleaned_sjp-tcfd-report-april2020.txt   ST. JAMES place   \n",
       "2    cleaned_sjp-tcfd-report-april2020.txt   ST. JAMES place   \n",
       "3    cleaned_sjp-tcfd-report-april2020.txt   ST. JAMES place   \n",
       "4    cleaned_sjp-tcfd-report-april2020.txt   ST. JAMES place   \n",
       "..                                     ...               ...   \n",
       "619   cleaned_Travelers_TCFDReport2023.txt  Traveler Cos TRV   \n",
       "620   cleaned_Travelers_TCFDReport2023.txt  Traveler Cos TRV   \n",
       "621   cleaned_Travelers_TCFDReport2023.txt  Traveler Cos TRV   \n",
       "622   cleaned_Travelers_TCFDReport2023.txt  Traveler Cos TRV   \n",
       "623   cleaned_Travelers_TCFDReport2023.txt  Traveler Cos TRV   \n",
       "\n",
       "                                             word_freq  \n",
       "0    [(climate, 26), (risk, 19), (opportunity, 7), ...  \n",
       "1    [(risk, 3), (investment, 3), (responsible, 2),...  \n",
       "2    [(climate, 5), (risk, 4), (st, 3), (place, 3),...  \n",
       "3    [(climate, 10), (investment, 4), (risk, 3), (r...  \n",
       "4    [(risk, 3), (change, 2), (opportunity, 2), (bu...  \n",
       "..                                                 ...  \n",
       "619  [(premium, 4), (insurance, 3), (oil, 2), (gas,...  \n",
       "620  [(energy, 14), (renewable, 11), (traveler, 4),...  \n",
       "621  [(carbon, 3), (premium, 3), (continue, 3), (tr...  \n",
       "622  [(vehicle, 7), (percentage, 5), (premium, 4), ...  \n",
       "623  [(energy, 4), (evolve, 3), (traveler, 2), (sup...  \n",
       "\n",
       "[624 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a list to hold the results\n",
    "most_frequent_words_per_file = []\n",
    "\n",
    "# Iterate over each unique file\n",
    "for _, row in paragraphs_df.iterrows():\n",
    "    text = row['paragraph']\n",
    "    file_name = row['file_name']\n",
    "    company = row['company_name']\n",
    "\n",
    "    # Tokenize and clean the text\n",
    "    tokens = clean_tokens_noun(pd.Series([text]))[0]\n",
    "\n",
    "    # Calculate word frequency\n",
    "    word_freq = Counter(tokens).most_common(5)\n",
    "\n",
    "    # Append the results to the list\n",
    "    most_frequent_words_per_file.append([file_name, company, word_freq])\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "frequent_words_per_file_df = pd.DataFrame(most_frequent_words_per_file, columns=['file_name', 'company_name', 'word_freq'])\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "frequent_words_per_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 45.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 195.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.17it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.11it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 242.49it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 179.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 21.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.07it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.97it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 233.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 331.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 202.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 392.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 232.65it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 201.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 195.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 257.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 358.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 331.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 286.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8176.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 231.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 226.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 209.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 200.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 22.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 186.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 170.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 333.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 223.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 249.08it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 224.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 249.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 225.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 151.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 151.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 194.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 192.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 236.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 195.93it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 351.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 313.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 188.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 248.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 554.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 237.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 185.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 221.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 266.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 178.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 246.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 171.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 918.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 167.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 193.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 241.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 274.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 206.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.96it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 453.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 197.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 177.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 343.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 171.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 455.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 22.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 267.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.85it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 189.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 435.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1101.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 213.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 409.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 164.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 197.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 238.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 901.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 581.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 243.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 248.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 716.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 614.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 215.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 191.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 156.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.28it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 175.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 191.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 188.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 185.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 258.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 156.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 184.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 167.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 170.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 277.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 252.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 240.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 248.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 928.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 499.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 192.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 265.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 203.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 222.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 722.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 240.24it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 240.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 178.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 174.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.25it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 275.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 238.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 249.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 20.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 392.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 240.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 401.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 577.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 292.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 317.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 262.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 307.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1181.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 964.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 826.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 232.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 683.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 165.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 178.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 176.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 164.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 571.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 218.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.46it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 151.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 898.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 271.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 211.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.76it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 239.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 396.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 206.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 216.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 317.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 208.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 255.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 197.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 346.55it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 227.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 324.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 445.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 256.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 164.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 258.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1109.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 714.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 300.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 205.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 177.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 218.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.93it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 437.00it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.96it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.27it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 609.46it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.18it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.33it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.15it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 244.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.16it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.65it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 252.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 330.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 444.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 197.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 175.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 258.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.27it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1496.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 181.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 276.96it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5005.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.33it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 332.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 25.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 185.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 202.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 151.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 247.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 258.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 170.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 198.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 179.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 249.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 226.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 200.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 331.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 224.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 311.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 422.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 260.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 179.15it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 171.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 279.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 206.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 172.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 203.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 155.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 155.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 174.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 427.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 188.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.74it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 172.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.75it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 193.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 167.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 278.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 175.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 845.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.58it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 260.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 232.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 164.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2680.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 332.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 225.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 401.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 214.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 164.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 194.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 261.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 68.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1815.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 465.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 295.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 333.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 253.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 235.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 130.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 186.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 474.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 62.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 596.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1059.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 156.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.92it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 184.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 185.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 197.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 190.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_clean</th>\n",
       "      <th>paragraph_noun</th>\n",
       "      <th>token</th>\n",
       "      <th>word_count</th>\n",
       "      <th>characters_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>commitment to help build a long -term future f...</td>\n",
       "      <td>commitment help build long future Force Climat...</td>\n",
       "      <td>commitment help recommendation climate risk di...</td>\n",
       "      <td>[commitment, help, build, long, future, force,...</td>\n",
       "      <td>89</td>\n",
       "      <td>626</td>\n",
       "      <td>10</td>\n",
       "      <td>7.033708</td>\n",
       "      <td>8.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>Group’s risk management frameworkEnsuring exec...</td>\n",
       "      <td>Group risk management frameworkensuring execut...</td>\n",
       "      <td>risk management execution investment principle...</td>\n",
       "      <td>[group, management, execution, responsible, in...</td>\n",
       "      <td>14</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>IndividualCross -function working group to dis...</td>\n",
       "      <td>individualcross work group discuss emerge ESG ...</td>\n",
       "      <td>work group activity climate risk opportunity m...</td>\n",
       "      <td>[work, group, discuss, emerge, st, place, acti...</td>\n",
       "      <td>38</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>6.736842</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have explained our approach to meeting thes...</td>\n",
       "      <td>explain approach meet objective documentour pe...</td>\n",
       "      <td>approach commitment governance framework frame...</td>\n",
       "      <td>[explain, approach, meet, objective, performan...</td>\n",
       "      <td>68</td>\n",
       "      <td>514</td>\n",
       "      <td>13</td>\n",
       "      <td>7.558824</td>\n",
       "      <td>5.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>We have facilitated regular cross -function di...</td>\n",
       "      <td>facilitate regular cross discussion identify p...</td>\n",
       "      <td>cross discussion eg increase frequency weather...</td>\n",
       "      <td>[facilitate, regular, cross, discussion, ident...</td>\n",
       "      <td>33</td>\n",
       "      <td>233</td>\n",
       "      <td>11</td>\n",
       "      <td>7.060606</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Importantly, all of our top  Oil &amp; Gas distrib...</td>\n",
       "      <td>importantly Oil Gas distribution partner sell ...</td>\n",
       "      <td>distribution partner traveler insurance produc...</td>\n",
       "      <td>[importantly, oil, gas, distribution, partner,...</td>\n",
       "      <td>24</td>\n",
       "      <td>178</td>\n",
       "      <td>4</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>O&amp;G Business Unit - Percentage of Total Travel...</td>\n",
       "      <td>Business Unit Percentage Total Travelers Domes...</td>\n",
       "      <td>business percentage total traveler traveler pr...</td>\n",
       "      <td>[business, unit, percentage, total, traveler, ...</td>\n",
       "      <td>71</td>\n",
       "      <td>486</td>\n",
       "      <td>8</td>\n",
       "      <td>6.845070</td>\n",
       "      <td>8.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>Travelers Underwriting Exposure to Carbon  Int...</td>\n",
       "      <td>traveler underwrite exposure Carbon Intensive ...</td>\n",
       "      <td>traveler exposure carbon sector classification...</td>\n",
       "      <td>[traveler, underwrite, exposure, carbon, inten...</td>\n",
       "      <td>24</td>\n",
       "      <td>166</td>\n",
       "      <td>4</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>The charts below illustrate the percentage of ...</td>\n",
       "      <td>chart illustrate percentage domestic premium a...</td>\n",
       "      <td>chart percentage premium associate carbon sect...</td>\n",
       "      <td>[chart, illustrate, percentage, domestic, prem...</td>\n",
       "      <td>34</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>7.617647</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>We believe  Travelers is well positioned to su...</td>\n",
       "      <td>believe traveler positioned support transition...</td>\n",
       "      <td>traveler support transition carbon economy tim...</td>\n",
       "      <td>[believe, traveler, positioned, support, trans...</td>\n",
       "      <td>34</td>\n",
       "      <td>244</td>\n",
       "      <td>7</td>\n",
       "      <td>7.176471</td>\n",
       "      <td>4.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name  date      company_name  \\\n",
       "0    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "2    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "3    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "4    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "..                                     ...   ...               ...   \n",
       "619   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "620   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "621   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "622   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "623   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                             paragraph  \\\n",
       "0    commitment to help build a long -term future f...   \n",
       "1    Group’s risk management frameworkEnsuring exec...   \n",
       "2    IndividualCross -function working group to dis...   \n",
       "3    We have explained our approach to meeting thes...   \n",
       "4    We have facilitated regular cross -function di...   \n",
       "..                                                 ...   \n",
       "619  Importantly, all of our top  Oil & Gas distrib...   \n",
       "620  O&G Business Unit - Percentage of Total Travel...   \n",
       "621  Travelers Underwriting Exposure to Carbon  Int...   \n",
       "622  The charts below illustrate the percentage of ...   \n",
       "623  We believe  Travelers is well positioned to su...   \n",
       "\n",
       "                                       paragraph_clean  \\\n",
       "0    commitment help build long future Force Climat...   \n",
       "1    Group risk management frameworkensuring execut...   \n",
       "2    individualcross work group discuss emerge ESG ...   \n",
       "3    explain approach meet objective documentour pe...   \n",
       "4    facilitate regular cross discussion identify p...   \n",
       "..                                                 ...   \n",
       "619  importantly Oil Gas distribution partner sell ...   \n",
       "620  Business Unit Percentage Total Travelers Domes...   \n",
       "621  traveler underwrite exposure Carbon Intensive ...   \n",
       "622  chart illustrate percentage domestic premium a...   \n",
       "623  believe traveler positioned support transition...   \n",
       "\n",
       "                                        paragraph_noun  \\\n",
       "0    commitment help recommendation climate risk di...   \n",
       "1    risk management execution investment principle...   \n",
       "2    work group activity climate risk opportunity m...   \n",
       "3    approach commitment governance framework frame...   \n",
       "4    cross discussion eg increase frequency weather...   \n",
       "..                                                 ...   \n",
       "619  distribution partner traveler insurance produc...   \n",
       "620  business percentage total traveler traveler pr...   \n",
       "621  traveler exposure carbon sector classification...   \n",
       "622  chart percentage premium associate carbon sect...   \n",
       "623  traveler support transition carbon economy tim...   \n",
       "\n",
       "                                                 token  word_count  \\\n",
       "0    [commitment, help, build, long, future, force,...          89   \n",
       "1    [group, management, execution, responsible, in...          14   \n",
       "2    [work, group, discuss, emerge, st, place, acti...          38   \n",
       "3    [explain, approach, meet, objective, performan...          68   \n",
       "4    [facilitate, regular, cross, discussion, ident...          33   \n",
       "..                                                 ...         ...   \n",
       "619  [importantly, oil, gas, distribution, partner,...          24   \n",
       "620  [business, unit, percentage, total, traveler, ...          71   \n",
       "621  [traveler, underwrite, exposure, carbon, inten...          24   \n",
       "622  [chart, illustrate, percentage, domestic, prem...          34   \n",
       "623  [believe, traveler, positioned, support, trans...          34   \n",
       "\n",
       "     characters_count  sentence_count  avg_word_length  avg_sentence_length  \n",
       "0                 626              10         7.033708             8.900000  \n",
       "1                 105               4         7.500000             3.500000  \n",
       "2                 256               8         6.736842             4.750000  \n",
       "3                 514              13         7.558824             5.230769  \n",
       "4                 233              11         7.060606             3.000000  \n",
       "..                ...             ...              ...                  ...  \n",
       "619               178               4         7.416667             6.000000  \n",
       "620               486               8         6.845070             8.875000  \n",
       "621               166               4         6.916667             6.000000  \n",
       "622               259               5         7.617647             6.800000  \n",
       "623               244               7         7.176471             4.857143  \n",
       "\n",
       "[624 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a list to hold the results\n",
    "most_frequent_words_per_file = []\n",
    "\n",
    "# Iterate over each unique file\n",
    "for _, row in paragraphs_df.iterrows():\n",
    "    text = row['paragraph']\n",
    "    file_name = row['file_name']\n",
    "    company = row['company_name']\n",
    "\n",
    "    # Tokenize and clean the text\n",
    "    tokens = clean_tokens_noun(pd.Series([text]))[0]\n",
    "\n",
    "    # Calculate word frequency\n",
    "    word_freq = Counter(tokens).most_common(5)\n",
    "    most_frequent_words = set(word for word, freq in word_freq)\n",
    "\n",
    "    # Append the results to the list\n",
    "    most_frequent_words_per_file.append([file_name, company, most_frequent_words])\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "frequent_words_per_file_df = pd.DataFrame(most_frequent_words_per_file, columns=['file_name', 'company_name', 'most_frequent_words'])\n",
    "\n",
    "# Remove the most frequent words from each token\n",
    "cleaned_tokens = []\n",
    "\n",
    "for _, row in paragraphs_df.iterrows():\n",
    "    text = row['paragraph']\n",
    "    tokens = clean_tokens_noun(pd.Series([text]))[0]\n",
    "\n",
    "    # Get the most frequent words for the current file\n",
    "    file_name = row['file_name']\n",
    "    company = row['company_name']\n",
    "    \n",
    "    # Filter to get frequent words for the current file\n",
    "    frequent_words_series = frequent_words_per_file_df[\n",
    "        (frequent_words_per_file_df['file_name'] == file_name) & \n",
    "        (frequent_words_per_file_df['company_name'] == company)\n",
    "    ]['most_frequent_words']\n",
    "    \n",
    "    if len(frequent_words_series) > 0:\n",
    "        frequent_words = frequent_words_series.values[0]  # Get the set of most frequent words\n",
    "    else:\n",
    "        frequent_words = set()\n",
    "\n",
    "    # Remove the most frequent words from tokens\n",
    "    cleaned_tokens.append([word for word in tokens if word not in frequent_words])\n",
    "\n",
    "# Update the 'token' column with cleaned tokens\n",
    "paragraphs_df['token'] = cleaned_tokens\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(len(paragraphs_df))\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "print(len(paragraphs_df))\n",
    "paragraphs_df['token_len'] = paragraphs_df['token'].apply(lambda x: len(x))\n",
    "# Drop rows where the length of the token is less than 2\n",
    "paragraphs_df = paragraphs_df[paragraphs_df['token_len'] > 2]\n",
    "print(len(paragraphs_df))\n",
    "# Recreate 'docs_tokens' from 'paragraphs_df'\n",
    "temp_token = paragraphs_df['token'] # .apply(remove_brackets)\n",
    "docs_tokens = []\n",
    "for i in temp_token:\n",
    "    docs_tokens.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Saving the Final DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script groups data by company and date and applies the splits. The resulting final DataFrames are saved as separate CSV files for each company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>company_name</th>\n",
       "      <th>token</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[commitment, help, build, long, future, force,...</td>\n",
       "      <td>commitment to help build a long -term future f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[group, management, execution, responsible, in...</td>\n",
       "      <td>Group’s risk management frameworkEnsuring exec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[work, group, discuss, emerge, st, place, acti...</td>\n",
       "      <td>IndividualCross -function working group to dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[explain, approach, meet, objective, performan...</td>\n",
       "      <td>We have explained our approach to meeting thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleaned_sjp-tcfd-report-april2020.txt</td>\n",
       "      <td>2020</td>\n",
       "      <td>ST. JAMES place</td>\n",
       "      <td>[facilitate, regular, cross, discussion, ident...</td>\n",
       "      <td>We have facilitated regular cross -function di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[importantly, oil, gas, distribution, partner,...</td>\n",
       "      <td>Importantly, all of our top  Oil &amp; Gas distrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[business, unit, percentage, total, traveler, ...</td>\n",
       "      <td>O&amp;G Business Unit - Percentage of Total Travel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[traveler, underwrite, exposure, carbon, inten...</td>\n",
       "      <td>Travelers Underwriting Exposure to Carbon  Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[chart, illustrate, percentage, domestic, prem...</td>\n",
       "      <td>The charts below illustrate the percentage of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>cleaned_Travelers_TCFDReport2023.txt</td>\n",
       "      <td>2023</td>\n",
       "      <td>Traveler Cos TRV</td>\n",
       "      <td>[believe, traveler, positioned, support, trans...</td>\n",
       "      <td>We believe  Travelers is well positioned to su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name  year      company_name  \\\n",
       "0    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "1    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "2    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "3    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "4    cleaned_sjp-tcfd-report-april2020.txt  2020   ST. JAMES place   \n",
       "..                                     ...   ...               ...   \n",
       "619   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "620   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "621   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "622   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "623   cleaned_Travelers_TCFDReport2023.txt  2023  Traveler Cos TRV   \n",
       "\n",
       "                                                 token  \\\n",
       "0    [commitment, help, build, long, future, force,...   \n",
       "1    [group, management, execution, responsible, in...   \n",
       "2    [work, group, discuss, emerge, st, place, acti...   \n",
       "3    [explain, approach, meet, objective, performan...   \n",
       "4    [facilitate, regular, cross, discussion, ident...   \n",
       "..                                                 ...   \n",
       "619  [importantly, oil, gas, distribution, partner,...   \n",
       "620  [business, unit, percentage, total, traveler, ...   \n",
       "621  [traveler, underwrite, exposure, carbon, inten...   \n",
       "622  [chart, illustrate, percentage, domestic, prem...   \n",
       "623  [believe, traveler, positioned, support, trans...   \n",
       "\n",
       "                                             paragraph  \n",
       "0    commitment to help build a long -term future f...  \n",
       "1    Group’s risk management frameworkEnsuring exec...  \n",
       "2    IndividualCross -function working group to dis...  \n",
       "3    We have explained our approach to meeting thes...  \n",
       "4    We have facilitated regular cross -function di...  \n",
       "..                                                 ...  \n",
       "619  Importantly, all of our top  Oil & Gas distrib...  \n",
       "620  O&G Business Unit - Percentage of Total Travel...  \n",
       "621  Travelers Underwriting Exposure to Carbon  Int...  \n",
       "622  The charts below illustrate the percentage of ...  \n",
       "623  We believe  Travelers is well positioned to su...  \n",
       "\n",
       "[624 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the final DataFrame with the specified columns\n",
    "tcfd = paragraphs_df[['file_name', 'date', 'company_name', 'token', 'paragraph']]\n",
    "\n",
    "# Rename the columns according to your specifications\n",
    "tcfd.columns = ['file_name', 'year', 'company_name', 'token', 'paragraph']\n",
    "\n",
    "# Display the DataFrame\n",
    "tcfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimi3\\AppData\\Local\\Temp\\ipykernel_20600\\1599291921.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tcfd['paragraph'] = tcfd['paragraph'].apply(clean_text)\n",
      "C:\\Users\\dimi3\\AppData\\Local\\Temp\\ipykernel_20600\\1599291921.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tcfd['token'] = tcfd['token'].apply(clean_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ST_JAMES_df to tcfd_company_csvs\\ST_JAMES_df.csv\n",
      "Saved Traveler_Cos_df to tcfd_company_csvs\\Traveler_Cos_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    # Check if the input is a string or a list\n",
    "    if isinstance(text, str):\n",
    "        # Replace common problematic characters\n",
    "        text = text.replace('β€™', \"'\")  # Replace specific problematic sequences\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    elif isinstance(text, list):\n",
    "        # If input is a list, return a cleaned list of tokens\n",
    "        return [clean_text(token) for token in text]\n",
    "    return text  # Return as is if not string or list\n",
    "\n",
    "# Rename columns as per your requirement\n",
    "tcfd = paragraphs_df[['file_name', 'date', 'company_name', 'token', 'paragraph']]\n",
    "tcfd.columns = ['file_name', 'year', 'company_name', 'token', 'paragraph']\n",
    "\n",
    "# Clean text in 'paragraph' column\n",
    "tcfd['paragraph'] = tcfd['paragraph'].apply(clean_text)\n",
    "\n",
    "# Clean text in 'token' column\n",
    "tcfd['token'] = tcfd['token'].apply(clean_text)\n",
    "\n",
    "# Group by 'company_name' to create separate DataFrames for each company\n",
    "company_dfs = {}\n",
    "for company in tcfd['company_name'].unique():\n",
    "    company_df = tcfd[tcfd['company_name'] == company][['file_name', 'year', 'token', 'paragraph']]\n",
    "    \n",
    "    # Sort DataFrame by 'year' in ascending order\n",
    "    company_df = company_df.sort_values(by='year', ascending=True)\n",
    "    \n",
    "    # Clean company name for CSV file naming\n",
    "    company_name_cleaned = \"_\".join(company.split()[:2]).replace('(', '').replace(')', '').replace('.', '').replace(',', '').replace(\"'\", \"\") + '_df'\n",
    "    \n",
    "    # Store the DataFrame in the dictionary\n",
    "    company_dfs[company_name_cleaned] = company_df\n",
    "\n",
    "# Function to get DataFrame by company name\n",
    "def get_company_df(company_name):\n",
    "    company_name_cleaned = \"_\".join(company_name.split()[:2]).replace('(', '').replace(')', '').replace('.', '').replace(',', '').replace(\"'\", \"\") + '_df'\n",
    "    return company_dfs.get(company_name_cleaned, None)\n",
    "\n",
    "# Save each company's DataFrame to a CSV file\n",
    "output_dir = \"tcfd_company_csvs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for company_name, df in company_dfs.items():\n",
    "    csv_path = os.path.join(output_dir, f\"{company_name}.csv\")\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8')  # Ensure UTF-8 encoding to handle special characters\n",
    "    print(f\"Saved {company_name} to {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
